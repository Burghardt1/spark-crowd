%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}





\title{spark-crowd Documentation}
\date{Oct 16, 2018}
\release{0.1.6}
\author{Enrique G. Rodrigo}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\maketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


Learning from crowdsourced Big Data


\bigskip\hrule\bigskip



\chapter{Quick Start}
\label{\detokenize{usage/quickstart:quick-start}}\label{\detokenize{usage/quickstart:quickstart}}\label{\detokenize{usage/quickstart::doc}}
You can start quickly using our package through our \sphinxhref{https://www.docker.com/}{docker} image or through \sphinxhref{https://spark-packages.org/}{spark-packages}.
See {\hyperref[\detokenize{usage/installation:installation}]{\sphinxcrossref{\DUrole{std,std-ref}{Installation}}}}, for all installation alternatives.


\section{Start with our docker image}
\label{\detokenize{usage/quickstart:start-with-our-docker-image}}
The quickest way to try our package is using the \sphinxhref{https://hub.docker.com/r/enriquegrodrigo/spark-crowd/}{provided docker image} image with the latest
version of our package, as you won’t need to install anything.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker pull enriquegrodrigo/spark\PYGZhy{}crowd
\end{sphinxVerbatim}

With it you can run the examples provided along with the \sphinxhref{https://github.com/enriquegrodrigo/spark-crowd}{package}. For example, to run \sphinxtitleref{DawidSkeneExample.scala}
we can use:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker run \PYGZhy{}\PYGZhy{}rm \PYGZhy{}it \PYGZhy{}v \PYG{k}{\PYGZdl{}(}\PYG{n+nb}{pwd}\PYG{k}{)}/:/home/work/project enriquegrodrigo/spark\PYGZhy{}crowd DawidSkeneExample.scala
\end{sphinxVerbatim}

You can also open a spark shell with the library preloaded.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
docker run \PYGZhy{}\PYGZhy{}rm \PYGZhy{}it \PYGZhy{}v \PYG{k}{\PYGZdl{}(}\PYG{n+nb}{pwd}\PYG{k}{)}/:/home/work/project enriquegrodrigo/spark\PYGZhy{}crowd
\end{sphinxVerbatim}

So you can test your code directly.


\section{Start with \sphinxtitleref{spark-packages}}
\label{\detokenize{usage/quickstart:start-with-spark-packages}}
If you have an installation of \sphinxhref{https://spark.apache.org/}{Apache Spark}  a you can open an \sphinxtitleref{spark-shell} using:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
spark\PYGZhy{}shell \PYGZhy{}\PYGZhy{}packages com.enriquegrodrigo:spark\PYGZhy{}crowd\PYGZus{}2.11:0.1.5
\end{sphinxVerbatim}

Likewise, you can submit an application that uses \sphinxtitleref{spark-crowd} using:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
spark\PYGZhy{}submit \PYGZhy{}\PYGZhy{}packages com.enriquegrodrigo:spark\PYGZhy{}crowd\PYGZus{}2.11:0.1.5 application.scala
\end{sphinxVerbatim}


\section{Basic usage}
\label{\detokenize{usage/quickstart:basic-usage}}
Once you have chosen your preferred installation procedure, you only need to import the corresponding method
that you want to use as well as the types for your data, as you can see below:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.methods.DawidSkene}
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.types.MulticlassAnnotation}

\PYG{k}{val} \PYG{n}{exampleFile} \PYG{k}{=} \PYG{l+s}{\PYGZdq{}examples/data/multi\PYGZhy{}ann.parquet\PYGZdq{}}

\PYG{k}{val} \PYG{n}{exampleData} \PYG{k}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{parquet}\PYG{o}{(}\PYG{n}{exampleFile}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{MulticlassAnnotation}\PYG{o}{]}

\PYG{c+c1}{//Applying the learning algorithm}
\PYG{k}{val} \PYG{n}{mode} \PYG{k}{=} \PYG{n+nc}{DawidSkene}\PYG{o}{(}\PYG{n}{exampleData}\PYG{o}{)}

\PYG{c+c1}{//Get MulticlassLabel with the class predictions}
\PYG{k}{val} \PYG{n}{pred} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getMu}\PYG{o}{(}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{MulticlassLabel}\PYG{o}{]}

\PYG{c+c1}{//Annotator precision matrices}
\PYG{k}{val} \PYG{n}{annprec} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getAnnotatorPrecision}\PYG{o}{(}\PYG{o}{)}
\end{sphinxVerbatim}

Let’s go through each step of the code:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
First we import the method, in this case \sphinxtitleref{DawidSkene} and the annotations type (\sphinxtitleref{MulticlassAnnotation}) that we will need
to load the data.

\item {} 
Then we load a data file (provided with the package) that contains annotations for different examples. We use the method \sphinxtitleref{as} to
to convert the Spark DataFrame in a typed Spark Dataset (with type \sphinxtitleref{MulticlassAnnotation}).

\item {} 
To execute the model and obtain the result we use the model name directly. This function returns a \sphinxtitleref{DawidSkeneModel}, that
includes the methods several methods to obtain results from the algorithm.

\item {} 
We use the  \sphinxtitleref{getMu} to obtain the ground truth estimations made by the model.

\item {} 
We use \sphinxtitleref{getAnnotatorPrecision} to obtain for the annotator precisions calculated by the model.

\end{enumerate}


\chapter{Installation}
\label{\detokenize{usage/installation:installation}}\label{\detokenize{usage/installation:id1}}\label{\detokenize{usage/installation::doc}}
You can use our package in your own developments in three ways:
\begin{itemize}
\item {} 
Using the package directly using spark-packages

\item {} 
Adding it as a dependency to your project through Maven central.

\item {} 
Compiling the source code and using the \sphinxcode{\sphinxupquote{jar}} file.

\end{itemize}

Alternatively, if you just want to execute simple scala scripts locally,
you can use our docker image as explained in {\hyperref[\detokenize{usage/quickstart:quickstart}]{\sphinxcrossref{\DUrole{std,std-ref}{Quick Start}}}}


\section{Using Spark Packages}
\label{\detokenize{usage/installation:using-spark-packages}}
The easiest way of using the package is through \sphinxhref{https://spark-packages.org/}{Spark Packages}, as you only need to add the package in the command line when running your
application:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
spark\PYGZhy{}submit \PYGZhy{}\PYGZhy{}packages com.enriquegrodrigo:spark\PYGZhy{}crowd\PYGZus{}2.11:0.1.5 application.scala
\end{sphinxVerbatim}

You can also open a \sphinxtitleref{spark-shell} using:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
spark\PYGZhy{}shell \PYGZhy{}\PYGZhy{}packages com.enriquegrodrigo:spark\PYGZhy{}crowd\PYGZus{}2.11:0.1.5
\end{sphinxVerbatim}

Likewise, you can submit an application that uses \sphinxtitleref{spark-crowd} using:


\section{Adding it as a dependency}
\label{\detokenize{usage/installation:adding-it-as-a-dependency}}
In addition to Spark Packages, the package is also in Maven Central, so you can add the package as a dependency in your scala project.
For example, in \sphinxstyleemphasis{sbt} you can add the dependency as shown below:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{libraryDependencies} \PYG{o}{+=} \PYG{l+s}{\PYGZdq{}com.enriquegrodrigo\PYGZdq{}} \PYG{o}{\PYGZpc{}\PYGZpc{}} \PYG{l+s}{\PYGZdq{}spark\PYGZhy{}crowd\PYGZdq{}} \PYG{o}{\PYGZpc{}} \PYG{l+s}{\PYGZdq{}0.1.5\PYGZdq{}}
\end{sphinxVerbatim}

This will allow you to use the methods inside your Apache Spark projects.


\section{Compiling the source code}
\label{\detokenize{usage/installation:compiling-the-source-code}}
To build the package using \sphinxstyleemphasis{sbt} you can use the following command inside the spark-crowd folder:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
sbt package
\end{sphinxVerbatim}

It will generate a compiled \sphinxcode{\sphinxupquote{jar}} file that you can add to your project.


\chapter{Design and architechture}
\label{\detokenize{package/design:design-and-architechture}}\label{\detokenize{package/design::doc}}
The package design can be found in the figure below.

\noindent\sphinxincludegraphics{{package}.png}

Although, the library contains several folders, the only folders important for the users
are the \sphinxcode{\sphinxupquote{types}} folder, and the \sphinxcode{\sphinxupquote{methods}}. The other folders contain auxiliary
functions some of the methods. Concretely, in interesting to explore the data types, as
they are key to understanding how the package works, as well as the common interface of
the methods.


\section{Data types}
\label{\detokenize{package/design:data-types}}
We provide types for annotations datasets and ground truth datasets, as they usually follow
the same structure. These types are used in all the methods so you would need to convert
your annotations dataset the correct format accepted by the algorithm.

There are three types of annotations that we support for which we provide Scala case classes,
making it possible to detect errors at compile time when using the algorithms:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{BinaryAnnotation}}: a Dataset of this type provides three columns, an example column, that
is the example for which the annotation is made, an annotator column, representing the
annotator that made the annotation and a value column, with the value of the annotation, that
can take value 0 or 1.

\item {} 
\sphinxcode{\sphinxupquote{MulticlassAnnotation}}: The difference form \sphinxcode{\sphinxupquote{BinaryAnnotation}} is that the value column can
take more than two values, in the range from 0 to the total number of values.

\item {} 
\sphinxcode{\sphinxupquote{RealAnnotation}}: In this case, the value column can take any numeric value.

\end{itemize}

You can convert an annotation dataframe with columns example, annotator and value to a
typed dataset easily with the following instruction:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{val} \PYG{n}{typedData} \PYG{k}{=} \PYG{n}{untypedData}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{RealAnnotation}\PYG{o}{]}
\end{sphinxVerbatim}

In the case of labels, we provide 5 types of labels, 2 of which are probabilistic. The three non probabilistic
types are:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{BinaryLabel}}: represents a dataset of example, value pairs where value is a binary value (0 or 1).

\item {} 
\sphinxcode{\sphinxupquote{MulticlassLabel}}: where value can take more than two values.

\item {} 
\sphinxcode{\sphinxupquote{RealLabel}}: where value can take any numeric value.

\end{itemize}

The probabilistic types are used by some algorithms, to provide more information about the confidence of each
class value for an specific example.
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{BinarySoftLabel}}: represents a dataset with two columns: example, and probability (prob). For each example, the probability
of positive is given.

\item {} 
\sphinxcode{\sphinxupquote{MultiSoftLabel}}: representas a dataset with three columns: example, class and probability (prob). For each example, there will be
several entries depending on the number of classes of the problem, with the probability estimate.

\end{itemize}


\section{Methods}
\label{\detokenize{package/design:methods}}
All methods implemented are in the \sphinxcode{\sphinxupquote{methods}} package and are mostly independent of each other. There is only one exception to this, the
use of the MajorityVoting algorithms, as most of the algorithms used these methods in the initialization step. Apart from that, all logic
is implemented in their specific files.  This makes it easier to extend the package with new algorithms. Although independent, all algorithms have
a similar interface, which facilitates its use. To execute an algorithm, the user normally needs to use the \sphinxcode{\sphinxupquote{apply}} method of the model, as shown below

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{k}{val} \PYG{n}{model} \PYG{k}{=} \PYG{n+nc}{IBCC}\PYG{o}{(}\PYG{n}{annotations}\PYG{o}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

After the model completes its execution, a model object is returned, which will have information about the ground truth estimations and
annotator’s quality and instance difficulties.

The only algorithm that do not follow this pattern is \sphinxcode{\sphinxupquote{MajorityVoting}}, which has methods for each of the class types and also to obtain
probabilistic labels. See the API Docs for details.


\chapter{Methods}
\label{\detokenize{package/methods:methods}}\label{\detokenize{package/methods::doc}}
You can find the methods implemented in this library below. All methods contain a link to its API where you
can find more information.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Methods implemented in spark-crowd}\label{\detokenize{package/methods:id1}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Method
&\sphinxstyletheadfamily 
Binary
&\sphinxstyletheadfamily 
Multiclass
&\sphinxstyletheadfamily 
Real
&\sphinxstyletheadfamily 
Reference
\\
\hline
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.MajorityVoting\$}{MajorityVoting}
&
\(\surd\)
&
\(\surd\)
&
\(\surd\)
&\\
\hline
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.DawidSkene\$}{DawidSkene}
&
\(\surd\)
&
\(\surd\)
&&
\sphinxhref{https://www.jstor.org/stable/2346806?seq=1\#page\_scan\_tab\_contents}{JRSS}
\\
\hline
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.GLAD\$}{GLAD}
&
\(\surd\)
&&&
\sphinxhref{https://papers.nips.cc/paper/3644-whose-vote-should-count-more-optimal-integration-of-labels-from-labelers-of-unknown-expertise}{NIPS}
\\
\hline
Raykar
&
\(\surd\)
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.RaykarBinary\$}{RaykarBinary}
&
\(\surd\)
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.RaykarBinary\$}{RaykarMulti}
&
\(\surd\)
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.RaykarBinary\$}{RaykarCont}
&
\sphinxhref{http://jmlr.csail.mit.edu/papers/v11/raykar10a.html}{JMLR}
\\
\hline
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.IBCC\$}{IBCC}
&
\(\surd\)
&
\(\surd\)
&&
\sphinxhref{http://proceedings.mlr.press/v22/kim12.html}{AISTATS}
\\
\hline
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.CATD\$}{CATD}
&&&
\(\surd\)
&
\sphinxhref{http://www.vldb.org/pvldb/vol8/p425-li.pdf}{VLDB}
\\
\hline
\sphinxhref{https://enriquegrodrigo.github.io/spark-crowd/\#com.enriquegrodrigo.spark.crowd.methods.PM\$}{PM}
&&&
\(\surd\)
&
\sphinxhref{https://dl.acm.org/citation.cfm?id=2588555.2610509}{SIGMOD}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\chapter{Examples}
\label{\detokenize{usage/examples:examples}}\label{\detokenize{usage/examples::doc}}
In this page we provide examples for several of the algorithms in the library.
You can find the data used for the examples in the Github repository.


\section{MajorityVoting}
\label{\detokenize{usage/examples:majorityvoting}}
Let’s start with the simpler algorithm to illustrate how to use the library, MajorityVoting:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.methods.MajorityVoting}
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.types.BinaryAnnotation}

\PYG{k}{val} \PYG{n}{exampleFile} \PYG{k}{=} \PYG{l+s}{\PYGZdq{}data/binary\PYGZhy{}ann.parquet\PYGZdq{}}

\PYG{k}{val} \PYG{n}{exampleDataBinary} \PYG{k}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{parquet}\PYG{o}{(}\PYG{n}{exampleFile}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{BinaryAnnotation}\PYG{o}{]}

\PYG{k}{val} \PYG{n}{muBinary} \PYG{k}{=} \PYG{n+nc}{MajorityVoting}\PYG{o}{.}\PYG{n}{transformBinary}\PYG{o}{(}\PYG{n}{exampleDataBinary}\PYG{o}{)}

\PYG{n}{muBinary}\PYG{o}{.}\PYG{n}{show}\PYG{o}{(}\PYG{o}{)}
\end{sphinxVerbatim}

This will show a result similar to this one:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+}
\PYG{o}{\textbar{}}\PYG{n}{example}\PYG{o}{\textbar{}}\PYG{n}{value}\PYG{o}{\textbar{}}
\PYG{o}{+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}+}
\PYG{o}{\textbar{}}     \PYG{l+m+mi}{26}\PYG{o}{\textbar{}}    \PYG{l+m+mi}{0}\PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}     \PYG{l+m+mi}{29}\PYG{o}{\textbar{}}    \PYG{l+m+mi}{1}\PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}    \PYG{l+m+mi}{474}\PYG{o}{\textbar{}}    \PYG{l+m+mi}{0}\PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}    \PYG{l+m+mi}{964}\PYG{o}{\textbar{}}    \PYG{l+m+mi}{1}\PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}     \PYG{l+m+mi}{65}\PYG{o}{\textbar{}}    \PYG{l+m+mi}{0}\PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}    \PYG{l+m+mi}{191}\PYG{o}{\textbar{}}    \PYG{l+m+mi}{0}\PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}    \PYG{l+m+mi}{418}\PYG{o}{\textbar{}}    \PYG{l+m+mi}{1}\PYG{o}{\textbar{}}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

MajorityVoting algorithms suppose that all annotators are equally accurate, so they choose the
most frequent annotation as the ground truth label. Therefore, they only return the ground
truth for the problem.

The data file in this example follow the format from the \sphinxcode{\sphinxupquote{BinaryAnnotation}} type:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{example}\PYG{o}{,} \PYG{n}{annotator}\PYG{o}{,} \PYG{n}{value}
      \PYG{l+m+mi}{0}\PYG{o}{,}         \PYG{l+m+mi}{0}\PYG{o}{,}     \PYG{l+m+mi}{1}
      \PYG{l+m+mi}{0}\PYG{o}{,}         \PYG{l+m+mi}{1}\PYG{o}{,}     \PYG{l+m+mi}{0}
      \PYG{l+m+mi}{0}\PYG{o}{,}         \PYG{l+m+mi}{2}\PYG{o}{,}     \PYG{l+m+mi}{1}
      \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

In this example, we use a \sphinxcode{\sphinxupquote{.parquet}} data file, which is usually a good option in terms of
efficiency. However, we do not limit the types of files you can use, as long as they can be
converted to typed datasets of \sphinxcode{\sphinxupquote{BinaryAnnotation}}, \sphinxcode{\sphinxupquote{MulticlassAnnotation}} or \sphinxcode{\sphinxupquote{RealAnnotation}}.
However, algorithms will suppose that there are no missing examples or annotators.

Concretely, MajorityVoting object can make predictions both for discrete classes (\sphinxcode{\sphinxupquote{BinaryAnnotation}} and
\sphinxcode{\sphinxupquote{MulticlassAnnotation}}) and continuous-valued target variables. (\sphinxcode{\sphinxupquote{RealAnnotation}}). You can find
information about these methods in the \sphinxhref{\_static/api/index.html}{API Docs}.


\section{DawidSkene}
\label{\detokenize{usage/examples:dawidskene}}
This algorithm is one of the most recommended for its ease of use as well as for it capabilities. It does not
have a great number of free parameters and obtains good results usually.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.methods.DawidSkene}
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.types.MulticlassAnnotation}

\PYG{k}{val} \PYG{n}{exampleFile} \PYG{k}{=} \PYG{l+s}{\PYGZdq{}examples/data/multi\PYGZhy{}ann.parquet\PYGZdq{}}

\PYG{k}{val} \PYG{n}{exampleData} \PYG{k}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{parquet}\PYG{o}{(}\PYG{n}{exampleFile}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{MulticlassAnnotation}\PYG{o}{]}

\PYG{k}{val} \PYG{n}{mode} \PYG{k}{=} \PYG{n+nc}{DawidSkene}\PYG{o}{(}\PYG{n}{exampleData}\PYG{o}{,} \PYG{n}{eMIters}\PYG{k}{=}\PYG{l+m+mi}{10}\PYG{o}{,} \PYG{n}{emThreshold}\PYG{k}{=}\PYG{l+m+mf}{0.001}\PYG{o}{)}

\PYG{k}{val} \PYG{n}{pred} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getMu}\PYG{o}{(}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{MulticlassLabel}\PYG{o}{]}

\PYG{k}{val} \PYG{n}{annprec} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getAnnotatorPrecision}\PYG{o}{(}\PYG{o}{)}
\end{sphinxVerbatim}

In our implementation, we use 2 parameters for controlling the algorithm execution, the maximum number
of EM iterations and the threshold for the likelihood change. The execution will stop if the it has reach
the established iterations or if the change in likelihood is less than the threshold. You do not need to
provided these parameters, as they have default values.

One executed, the model will provide us with an estimation of the ground truth, taking into account the
annotations and the quality of each annotator. We can access this information as shown on the example.
Concretely, the provided annotator precision is a three dimensional array with, first dimension representing
the annotator and the second and third, the confusion matrix for the annotator.


\section{GLAD}
\label{\detokenize{usage/examples:glad}}
The GLAD algorithm is interesting as it provides both annotator accuracies and example difficulties obtained
solely from the annotations. Here is an example of how to use it:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.methods.Glad}
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.types.BinaryAnnotation}

\PYG{k}{val} \PYG{n}{annFile} \PYG{k}{=} \PYG{l+s}{\PYGZdq{}data/binary\PYGZhy{}ann.parquet\PYGZdq{}}

\PYG{k}{val} \PYG{n}{annData} \PYG{k}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{parquet}\PYG{o}{(}\PYG{n}{annFile}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{BinaryAnnotation}\PYG{o}{]}

\PYG{k}{val} \PYG{n}{mode} \PYG{k}{=} \PYG{n+nc}{Glad}\PYG{o}{(}\PYG{n}{annData}\PYG{o}{,}
                  \PYG{n}{eMIters}\PYG{k}{=}\PYG{l+m+mi}{5}\PYG{o}{,} \PYG{c+c1}{//Maximum number of iterations of EM algorithm}
                  \PYG{n}{eMThreshold}\PYG{k}{=}\PYG{l+m+mf}{0.1}\PYG{o}{,} \PYG{c+c1}{//Threshold for likelihood changes}
                  \PYG{n}{gradIters}\PYG{k}{=}\PYG{l+m+mi}{30}\PYG{o}{,} \PYG{c+c1}{//Gradient descent max number of iterations}
                  \PYG{n}{gradTreshold}\PYG{k}{=}\PYG{l+m+mf}{0.5}\PYG{o}{,} \PYG{c+c1}{//Gradient descent threshold}
                  \PYG{n}{gradLearningRate}\PYG{k}{=}\PYG{l+m+mf}{0.01}\PYG{o}{,} \PYG{c+c1}{//Gradient descent learning rate}
                  \PYG{n}{alphaPrior}\PYG{k}{=}\PYG{l+m+mi}{1}\PYG{o}{,} \PYG{c+c1}{//Alpha first value (GLAD specific)}
                  \PYG{n}{betaPrior}\PYG{k}{=}\PYG{l+m+mi}{1}\PYG{o}{)} \PYG{c+c1}{//Beta first value (GLAD specific)}

\PYG{k}{val} \PYG{n}{pred} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getMu}\PYG{o}{(}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{BinarySoftLabel}\PYG{o}{]}

\PYG{k}{val} \PYG{n}{annprec} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getAnnotatorPrecision}\PYG{o}{(}\PYG{o}{)}

\PYG{k}{val} \PYG{n}{annprec} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getInstanceDifficulty}\PYG{o}{(}\PYG{o}{)}
\end{sphinxVerbatim}

This model as it is implemented in the library is only compatible with binary class problems. It has a
higher number of free parameters in comparison with the previous algorithm, but we provided default
values for all of them for convenience. The meaning of each of these parameters is commented in the
example above, as it is on the documentation. The annotator precision is given in a vector, with an
entry for each annotator. The difficulty is given in the form of a DataFrame, returning
a difficulty value for each example. For more information about this you can consult the documentation
and/or the paper.


\section{RaykarBinary, RaykarMulti and RaykarCont}
\label{\detokenize{usage/examples:raykarbinary-raykarmulti-and-raykarcont}}
We implement the three variants of this algorithm, for discrete and continuous target variables.
These algorithms have in common that they are able to use features to estimate the ground truth
and even learn a linear model. The model also is able to use prior information about annotators,
which can be useful to add more confidence to certain annotators. In the next example we show
how to use this model adding a prior that indicates that we trust a lot in the first annotator
and that we now that the second annotator is not reliable.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.methods.RaykarBinary}
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.types.BinaryAnnotation}

\PYG{k}{val} \PYG{n}{exampleFile} \PYG{k}{=} \PYG{l+s}{\PYGZdq{}data/binary\PYGZhy{}data.parquet\PYGZdq{}}
\PYG{k}{val} \PYG{n}{annFile} \PYG{k}{=} \PYG{l+s}{\PYGZdq{}data/binary\PYGZhy{}ann.parquet\PYGZdq{}}

\PYG{k}{val} \PYG{n}{exampleData} \PYG{k}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{parquet}\PYG{o}{(}\PYG{n}{exampleFile}\PYG{o}{)}
\PYG{k}{val} \PYG{n}{annData} \PYG{k}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{parquet}\PYG{o}{(}\PYG{n}{annFile}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{BinaryAnnotation}\PYG{o}{]}

\PYG{c+c1}{//Preparing priors}
\PYG{k}{val} \PYG{n}{nAnn} \PYG{k}{=} \PYG{n}{annData}\PYG{o}{.}\PYG{n}{map}\PYG{o}{(}\PYG{k}{\PYGZus{}}\PYG{o}{.}\PYG{n}{annotator}\PYG{o}{)}\PYG{o}{.}\PYG{n}{distinct}\PYG{o}{.}\PYG{n}{count}\PYG{o}{(}\PYG{o}{)}\PYG{o}{.}\PYG{n}{toInt}

\PYG{k}{val} \PYG{n}{a} \PYG{k}{=} \PYG{n+nc}{Array}\PYG{o}{.}\PYG{n}{fill}\PYG{o}{[}\PYG{k+kt}{Double}\PYG{o}{]}\PYG{o}{(}\PYG{n}{nAnn}\PYG{o}{,}\PYG{l+m+mi}{2}\PYG{o}{)}\PYG{o}{(}\PYG{l+m+mf}{2.0}\PYG{o}{)} \PYG{c+c1}{//Uniform prior}
\PYG{k}{val} \PYG{n}{b} \PYG{k}{=} \PYG{n+nc}{Array}\PYG{o}{.}\PYG{n}{fill}\PYG{o}{[}\PYG{k+kt}{Double}\PYG{o}{]}\PYG{o}{(}\PYG{n}{nAnn}\PYG{o}{,}\PYG{l+m+mi}{2}\PYG{o}{)}\PYG{o}{(}\PYG{l+m+mf}{2.0}\PYG{o}{)} \PYG{c+c1}{//Uniform prior}

\PYG{c+c1}{//Give first annotator more confidence}
\PYG{n}{a}\PYG{o}{(}\PYG{l+m+mi}{0}\PYG{o}{)}\PYG{o}{(}\PYG{l+m+mi}{0}\PYG{o}{)} \PYG{o}{+=} \PYG{l+m+mi}{1000}
\PYG{n}{b}\PYG{o}{(}\PYG{l+m+mi}{0}\PYG{o}{)}\PYG{o}{(}\PYG{l+m+mi}{0}\PYG{o}{)} \PYG{o}{+=} \PYG{l+m+mi}{1000}

\PYG{c+c1}{//Give second annotator less confidence}
\PYG{c+c1}{//Annotator 1}
\PYG{n}{a}\PYG{o}{(}\PYG{l+m+mi}{1}\PYG{o}{)}\PYG{o}{(}\PYG{l+m+mi}{1}\PYG{o}{)} \PYG{o}{+=} \PYG{l+m+mi}{1000}
\PYG{n}{b}\PYG{o}{(}\PYG{l+m+mi}{1}\PYG{o}{)}\PYG{o}{(}\PYG{l+m+mi}{1}\PYG{o}{)} \PYG{o}{+=} \PYG{l+m+mi}{1000}


\PYG{c+c1}{//Applying the learning algorithm}
\PYG{k}{val} \PYG{n}{mode} \PYG{k}{=} \PYG{n+nc}{RaykarBinary}\PYG{o}{(}\PYG{n}{exampleData}\PYG{o}{,} \PYG{n}{annData}\PYG{o}{,}
                          \PYG{n}{eMIters}\PYG{k}{=}\PYG{l+m+mi}{5}\PYG{o}{,}
                          \PYG{n}{eMThreshold}\PYG{k}{=}\PYG{l+m+mf}{0.001}\PYG{o}{,}
                          \PYG{n}{gradIters}\PYG{k}{=}\PYG{l+m+mi}{100}\PYG{o}{,}
                          \PYG{n}{gradThreshold}\PYG{k}{=}\PYG{l+m+mf}{0.1}\PYG{o}{,}
                          \PYG{n}{gradLearning}\PYG{k}{=}\PYG{l+m+mf}{0.1}
                          \PYG{n}{a\PYGZus{}prior}\PYG{k}{=}\PYG{n+nc}{Some}\PYG{o}{(}\PYG{n}{a}\PYG{o}{)}\PYG{o}{,} \PYG{n}{b\PYGZus{}prior}\PYG{k}{=}\PYG{n+nc}{Some}\PYG{o}{(}\PYG{n}{b}\PYG{o}{)}\PYG{o}{)}

\PYG{c+c1}{//Get MulticlassLabel with the class predictions}
\PYG{k}{val} \PYG{n}{pred} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getMu}\PYG{o}{(}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{BinarySoftLabel}\PYG{o}{]}

\PYG{c+c1}{//Annotator precision matrices}
\PYG{k}{val} \PYG{n}{annprec} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{getAnnotatorPrecision}\PYG{o}{(}\PYG{o}{)}
\end{sphinxVerbatim}

Apart form the features matrix and the priors, the meaning of the parameters is the same as in the previous examples.
The priors are matrices of A by 2. In each row we have the hyperparameters of a Beta distribution for each annotator.
The \sphinxcode{\sphinxupquote{a\_prior}} gives prior information about the ability of annotators to classify correctly a positive example. The
\sphinxcode{\sphinxupquote{b\_prior}} does the same thing but for the negative examples. More information about this method as well as the methods
for discrete and continuous target variables can be found in the API docs.


\section{CATD}
\label{\detokenize{usage/examples:catd}}
This method allows to estimate continuous-value target variables from annotations.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.methods.CATD}
\PYG{k}{import} \PYG{n+nn}{com.enriquegrodrigo.spark.crowd.types.RealAnnotation}

\PYG{n}{sc}\PYG{o}{.}\PYG{n}{setCheckpointDir}\PYG{o}{(}\PYG{l+s}{\PYGZdq{}checkpoint\PYGZdq{}}\PYG{o}{)}

\PYG{k}{val} \PYG{n}{annFile} \PYG{k}{=} \PYG{l+s}{\PYGZdq{}examples/data/cont\PYGZhy{}ann.parquet\PYGZdq{}}

\PYG{k}{val} \PYG{n}{annData} \PYG{k}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{parquet}\PYG{o}{(}\PYG{n}{annFile}\PYG{o}{)}\PYG{o}{.}\PYG{n}{as}\PYG{o}{[}\PYG{k+kt}{RealAnnotation}\PYG{o}{]}

\PYG{c+c1}{//Applying the learning algorithm}
\PYG{k}{val} \PYG{n}{mode} \PYG{k}{=} \PYG{n+nc}{CATD}\PYG{o}{(}\PYG{n}{annData}\PYG{o}{,} \PYG{n}{iterations}\PYG{k}{=}\PYG{l+m+mi}{5}\PYG{o}{,}
                          \PYG{n}{threshold}\PYG{k}{=}\PYG{l+m+mf}{0.1}\PYG{o}{,}
                          \PYG{n}{alpha}\PYG{k}{=}\PYG{l+m+mf}{0.05}\PYG{o}{)}

\PYG{c+c1}{//Get MulticlassLabel with the class predictions}
\PYG{k}{val} \PYG{n}{pred} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{mu}

\PYG{c+c1}{//Annotator precision matrices}
\PYG{k}{val} \PYG{n}{annprec} \PYG{k}{=} \PYG{n}{mode}\PYG{o}{.}\PYG{n}{weights}
\end{sphinxVerbatim}

It returns a model from which you can get the ground truth estimation and
also the annotator weight used (more weight would signify a better annotator).
The algorithm uses parameters such as \sphinxcode{\sphinxupquote{iterations}} and \sphinxcode{\sphinxupquote{threshold}} for
controlling the execution, and also \sphinxcode{\sphinxupquote{alpha}}, which is a parameter of the model
(check the API docs for more information).


\chapter{Comparison with other packages}
\label{\detokenize{package/other:comparison-with-other-packages}}\label{\detokenize{package/other::doc}}
There exists other packages implementing similar methods in other languages, but with
different goals in mind. To our knowledge, there are 2 software packages with the goal
of learning from crowdsourced data:
\begin{itemize}
\item {} 
\sphinxhref{http://ceka.sourceforge.net/}{Ceka}: it is a Java software package based on WEKA, with
a great number of methods that can be used to learn from crowdsource data.

\item {} 
\sphinxhref{https://zhydhkcws.github.io/crowd\_truth\_inference/index.html/}{Truth inference in Crowdsourcing} makes available a collection
of methods in Python to learn from crowdsourced data.

\end{itemize}

Both are useful packages when dealing with crowdsourced data, with a focus on research. \sphinxtitleref{spark-crowd} is different, in the sense that
not only is useful in research, but in production as well, providing tests for all of its methods with a high test coverage. Moreover,
methods have been implemented with a focus on scalability, so it is useful in a wide variety of situations. We provide a
comparison of the methods over a set of datasets next, taking into account both quality of the models and execution time.


\section{Data}
\label{\detokenize{package/other:data}}
For this performance test we use simulated datasets of increasing size:
\begin{itemize}
\item {} 
\sphinxstylestrong{binary1-4}: simulated binary class datasets with 10K, 100K, 1M and 10M instances respectively. Each of them
has 10 simulated annotations per instance, and the ground truth for each example is known (but not used in the
learning process). The accuracy shown in the tables is obtained over this known ground truth.

\item {} 
\sphinxstylestrong{cont1-4}: simulated continuous target variable datasets, with 10k, 100k, 1M and 10M instances respectively. Each of them
has 10 simulated annotations per instance, and the ground truth for each example is known (but not used in the
learning process). The Mean Absolute Error is obtained over this known ground truth.

\item {} 
\sphinxstylestrong{crowdscale}. A real multiclass dataset from the \sphinxstyleemphasis{Crowdsourcing at Scale} challenge. The data is comprised of 98979 instances,
evaluated by, at least, 5 annotators, for a total of 569375 answers. We only have ground truth for the 0.3\% of the data,
which is used for evaluation.

\end{itemize}

All datasets are available through this {\color{red}\bfseries{}{}`link \textless{}\textgreater{}{}`\_}


\section{CEKA}
\label{\detokenize{package/other:id1}}
To compare our methods with Ceka, we used two of the main methods implemented in both packages, MajorityVoting and DawidSkene. Ceka and
spark-crowd also implement GLAD and Raykar’s algorithms. However, in Ceka, these algorithms are implemented using wrappers to other libraries.
The library for the GLAD algorithm is not available on our platform, as it is given as an EXE Windows file, and the wrapper for Raykar’s algorithms
does not admit any configuration parameters.

We provide the results of the execution of these methods in terms of accuracy (Acc) and time (in seconds). For our package, we also include
the execution time for a cluster (tc) with 3 executor nodes of 10 cores and 30Gb of memory each.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Comparison with Ceka}\label{\detokenize{package/other:id3}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily &\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{11}}
\sphinxstyletheadfamily MajorityVoting
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{11}}
\sphinxstyletheadfamily DawidSkene
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily &\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{11}}
\sphinxstyletheadfamily Ceka
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{11}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{11}}
\sphinxstyletheadfamily Ceka
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{11}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily 
Method
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
\\
\hline
binary1
&
0.931
&
21
&
0.931
&
11
&
7
&
0.994
&
57
&
0.994
&
31
&
32
\\
\hline
binary2
&
0.936
&
15983
&
0.936
&
11
&
7
&
0.994
&
49259
&
0.994
&
181
&
43
\\
\hline
binary3
&
X
&
X
&
0.936
&
21
&
8
&
X
&
X
&
0.994
&
696
&
87
\\
\hline
binary4
&
X
&
X
&
0.936
&
84
&
42
&
X
&
X
&
0.994
&
1033
&
86
\\
\hline
crowdscale
&
0.88
&
10458
&
0.9
&
13
&
7
&
0.89
&
30999
&
0.9033
&
447
&
86
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Regarding accuracy, both packages achieve comparable results. However, regarding execution time, spark-crowd obtains
significantly better results among all datasets especially on the bigger datasets, where it can solve problems that
Ceka is not able to. You can see the speedup results in the table below.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Speedup in comparison to Ceka}\label{\detokenize{package/other:id4}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily &\sphinxstartmulticolumn{4}%
\begin{varwidth}[t]{\sphinxcolwidth{4}{5}}
\sphinxstyletheadfamily MajorityVoting  \textbar{}      DawidSkene
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily 
Method
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
\\
\hline
binary1
&
1.86
&
2.93
&
1.84
&
1.78
\\
\hline
binary2
&
1453
&
2283
&
272
&
1146
\\
\hline
crowdscale
&
804
&
1494
&
69
&
360
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

We can see that spark-crowd obtains a high speedup in bigger datasets and performs
slightly better in the smaller ones.


\section{Truth inference in crowdsourcing}
\label{\detokenize{package/other:id2}}
Now we compare spark-crowd with the methods available in this paper. Although the methods
can certainly be used for to compare and try the algorithms, the integration of these
methods into a large ecosystem will be very difficult, as the authors do not provide
a software package structure. However, as it is an available package with a great number
of methods, a comparison with them is needed. We will use the same datasets
as the ones used in the previous comparison. In this case, we can compare a higher
number of models, as most of the methods are written in python. However, we were only able
to execute the methods over datasets with binary or continuous target variables. As far as we
know, the use of multiclass target variables seems to not be possible. Moreover, the use of
feature sets is also restricted, although algorithms that should be capable of dealing with
this kind of data are implemented, as is the case with the Raykar’s methods.

First, we compare the algorithms capable of learning from binary classes without feature sets.
Inside this category, we will compare MajorityVoting, DawidSkene, GLAD and IBCC. We show the results
in terms of Accuracy (Acc) and time (in seconds) in the table below.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Comparative with Truth inference in Crowdsourcing package}\label{\detokenize{package/other:id5}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily &\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{21}}
\sphinxstyletheadfamily MajorityVoting
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{21}}
\sphinxstyletheadfamily DawidSkene
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{21}}
\sphinxstyletheadfamily GLAD
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{21}}
\sphinxstyletheadfamily IBCC
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily &\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{21}}
\sphinxstyletheadfamily Truth-inf
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{21}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{21}}
\sphinxstyletheadfamily Truth-inf
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{21}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{21}}
\sphinxstyletheadfamily Truth-inf
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{21}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{21}}
\sphinxstyletheadfamily Truth-inf
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{21}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily 
Method
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
\\
\hline
binary1
&
0.931
&
1
&
0.931
&
11
&
7
&
0.994
&
12
&
0.994
&&&
0.994
&
1185
&
0.994
&&&
0.994
&
22
&
0.994
&&\\
\hline
binary2
&
0.936
&
8
&
0.936
&
11
&
7
&
0.994
&
161
&
0.994
&&&
0.994
&
4168
&
0.994
&&&
0.994
&
372
&
0.994
&&\\
\hline
binary3
&
0.936
&
112
&
0.936
&
21
&
8
&
0.994
&
1705
&
0.994
&&&
X
&
X
&
0.994
&&&
0.994
&
25764
&
0.994
&&\\
\hline
binary4
&
0.936
&
2908
&
0.936
&
13
&
7
&
M
&
M
&
0.994
&&&
X
&
X
&
0.994
&&&
X
&
X
&
X
&&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Next we analize methods that are able to learn from continuous target variables: MajorityVoting (mean), CATD and PM (with mean initialization). We show the results in terms of MAE (Mean absolute error) and time (in seconds).


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Comparative with Truth inference in Crowdsourcing package}\label{\detokenize{package/other:id6}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily &\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{16}}
\sphinxstyletheadfamily MajorityVoting (mean)
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{16}}
\sphinxstyletheadfamily CATD
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{5}%
\begin{varwidth}[t]{\sphinxcolwidth{5}{16}}
\sphinxstyletheadfamily PM
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily &\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{16}}
\sphinxstyletheadfamily Truth-inf
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{16}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{16}}
\sphinxstyletheadfamily Truth-inf
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{16}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{16}}
\sphinxstyletheadfamily Truth-inf
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{16}}
\sphinxstyletheadfamily spark-crowd
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily 
Method
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
Acc
&\sphinxstyletheadfamily 
t1
&\sphinxstyletheadfamily 
tc
\\
\hline
cont1
&
1.234
&&
1.234
&&&
0.324
&&
0.324
&&&
0.495
&&
0.495
&&\\
\hline
cont2
&
1.231
&&
1.231
&&&
0.321
&&
0.321
&&&
0.493
&&
0.495
&&\\
\hline
cont3
&
1.231
&&
1.231
&&&
X
&
X
&
0.322
&&&
X
&&
0.494
&&\\
\hline
cont4
&
1.231
&&
1.231
&&&
X
&
X
&
0.322
&&&
X
&&
0.494
&&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\chapter{Contributors}
\label{\detokenize{package/contributors:contributors}}\label{\detokenize{package/contributors::doc}}
We are open to contributions in the form of bugs reports, enhancements or even new algorithms.


\section{Bug reports}
\label{\detokenize{package/contributors:bug-reports}}
Bugs are tracked using Github issues. When creating a bug report, try to provide as much information as possible to help maintainers
reproduce the problem
\begin{itemize}
\item {} 
Use a clear and descriptive title for the issue to identify the problem.

\item {} 
Describe the exact steps which reproduce the problem in as many details as possible. For example, start by explaining how you prepared the data as well as how the package was installed and what version of the package are you using. When listing steps, don’t just say what you did, but explain how you did it.

\item {} 
Provide specific examples to demonstrate the steps. Include links to files or GitHub projects. If you’re providing snippets in the issue, use Markdown code blocks.

\item {} 
Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior.

\item {} 
Explain which behavior you expected to see instead and why.

\item {} 
If the problem is related to performance or memory, include a CPU profile capture with your report.

\end{itemize}

Provide more context by answering these questions:
\begin{itemize}
\item {} 
Did the problem start happening recently (e.g. after updating the version dependencies) or was this always a problem?

\item {} 
If the problem started happening recently, can you reproduce the problem in an older version? What’s the most recent version in which the problem doesn’t happen?

\item {} 
Can you reliably reproduce the issue? If not, provide details about how often the problem happens and under which conditions it normally happens.

\end{itemize}

Include details about your configuration and environment:
\begin{itemize}
\item {} 
Which version of spark-crowd are you using?

\item {} 
What’s the name and version of the OS you’re using?

\item {} 
Are you running using the package in a virtual machine? If so, which VM software are you using and which operating systems and versions are used for the host and the guest?

\end{itemize}


\section{Suggesting enhancements}
\label{\detokenize{package/contributors:suggesting-enhancements}}
We are open to suggestions of new features and minor improvements to existing functionality. Please follow the guidelines to help maintainers and the community
understand your suggestion. When requesting and enhancement please include as many details as possible.

Enhancement suggestions are tracked using Github Issues. To request an enhancement create an issue and provide the following information.
\begin{itemize}
\item {} 
Use a clear and descriptive title for the issue to identify the suggestion.

\item {} 
Provide a step-by-step description of the suggested enhancement in as many details as possible.

\item {} 
Provide specific examples to demonstrate the steps. Include copy/pasteable snippets which you use in those examples, as Markdown code blocks.

\item {} 
Describe the current behavior and explain which behavior you expected to see instead and why.

\item {} 
Explain why this enhancement would be useful to the users.

\item {} 
Specify which version of the package you’re using. Specify the name and version of the OS you’re using.

\end{itemize}


\section{New algorithms}
\label{\detokenize{package/contributors:new-algorithms}}
We are also grateful for contributions of new algorithms, as long as they improve the results or add new functionality to the ones existing in the package.
New algorithms must be published in peer-review publications for them to be considered. New algorithms must adhere to the architechture of this package and
should take into account the scalability of the learning process.

To contribute an algorithm first create a request using Github Issues, for the maintainers to review the suggestion. This request should provide the following information:
\begin{itemize}
\item {} 
Publication where the algorithm detais can be reviewed.

\item {} 
Explain why this algorithm would be useful to the users.

\end{itemize}

If the request is accepted, create a Github pull request with the new algorithm, as well as all necessary types to use it, so that the maintainers can review the
code and add it to the package.

Learning from crowdsourced data imposes new challenges
in the area of machine learning. \sphinxtitleref{spark-crowd} practitioners
when dealing with this kind of data at scale, using Apache Spark.

\noindent\sphinxincludegraphics{{illustration}.png}

The main features of \sphinxtitleref{spark-crowd} are the following:
\begin{itemize}
\item {} 
It implements well-known methods for learning from crowdsourced labeled data.

\item {} 
It is suitable for working with both large and small datasets.

\item {} 
It uses Apache Spark, which allows the code to run in different environments, from a computer to a multi-node cluster.

\item {} 
It is suitable both for research and production environments.

\item {} 
It provides an easy to use API, allowing the practitioner to start using the library in minutes.

\end{itemize}

See the {\hyperref[\detokenize{usage/quickstart:quickstart}]{\sphinxcrossref{\DUrole{std,std-ref}{Quick Start}}}} to get started using \sphinxtitleref{spark-crowd}

\sphinxtitleref{spark-crowd} is licensed under the \sphinxhref{https://opensource.org/licenses/MIT/}{MIT license}.



\renewcommand{\indexname}{Index}
\printindex
\end{document}